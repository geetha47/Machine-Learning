***Machine Learning Model Comparison on Small Dataset***
**Overview**

This project aimed to compare the performance of various machine learning models on a small dataset containing approximately 400 samples. The objective was to identify the most effective model for classification tasks on this particular dataset.

**Dataset**
The sample dataset consists of features like age, estimated salary and taget variable is based on whether the persons purchased the product or not. The preprocessing steps undertaken, such as data cleaning, feature scaling, or encoding categorical variables.

**Models Evaluated**
The machine learning models that were evaluated in this experiment:
Logistic Regression
Support Vector Machine with RBF Kernel
Multi-layer Perceptron Classifier
Naive Bayes Classifier
K-Nearest Neighbors Classifier
Random Forest Classifier
Decision Tree Classifier
Gradient Boosting Classifier

**Results**
A summary of the performance metrics obtained for each model.
SVM with RBF Kernel: 95% accuracy
MLP and Naive Bayes: 94% accuracy
KNN and Random Forest: 90-92% accuracy

Overall, SVM with RBF kernel demonstrated the best performance in this experiment scoring accuracy of 95%. Its ability to handle non-linearities well in the data contributed to this success. Following closely behind, naive bayes classifiers and MLP with 94% for its ability to analyse complex patterns, while Naive Bayes benefits from its assumption of strong independence between features. Additionally, both KNN and Random Forest classifiers exhibited respectable performance, with accuracies ranging from 90% to 92%. This demonstrates their effectiveness in handling small datasets and diverse types of data.
